---
layout: default
title: DREAMT | Reranking
---
<div class="page-header">
  <h1>Reranking<font color="lightgrey"> : Challenge Problem 4</font></h1>
</div>

<p>In <a href="challenge2.html">Challenge 2</a> you saw that search could find
more probable translations, but this most useful when you have a good model.
In <a href="challenge3.html">Challenge 3</a> you saw that it was possible
to create a metric that correlated (at least somewhat) with human assessments
of machine translation systems. Armed with such a metric, you are now in
a position to quantitatively evaluate machine translation output, which is 
an important step to creating a better model. In this assignment,
you will be given a set of N-best candidate translations for each sentence
of a French test set, and you will create a model to choose the best one.
<b>Your goal is to improve the translation quality by choosing better
translations</b>.

<h2>Getting Started</h2>

<p>If you already have a clone of the repository from the previous challenges 
you are ready to start. If not, clone a fresh version of the repository by running:</p>

<p><pre>git clone https://github.com/alopez/dreamt.git</pre></p>

<p>Under the <tt>rerank</tt> directory, We have provided you with a very 
simple reranking program written in Python and a few utility programs. 
There is also a directory containing training and test datasets. Each dataset 
consists of many alternative machine translations for each sentence of the 
input data. To see the available translations of the 500 French sentences in
<tt>data/test.fr</tt>, take a look at the file
<tt>data/test.nbest</tt>. Each line contains a sentence number, a translation,
and a set of feature values for that translation that were provided by a
state-of-the-art translation model. The goal of the reranking program is to choose the
best translation from among the many alternatives in the file. By default, 
the reranker weights all of the feature values uniformly and scores each 
candidate by their weighted sum. It then outputs the candidate with the 
minimum cost. To run it, type:
</p>

<p><pre>rerank &gt; output</pre></p>

<p>This runs the reranker and stores the set of sentences that it deems to be
best in the file named <tt>output</tt>. We have additionally provided you with
a program that calculates the BLEU score of the first 250 sentences of the 
test set from a set of human reference translations in <tt>data/test.en</tt>. 
Run this command:
</p>

<p><pre>grade &lt; output</pre></p>

<p>It is possible to do much better than the 
default reranker! To see this, run the command:
</p>

<p><pre>oracle | grade</pre></p>

<p>The oracle uses the human reference translations to choose sentences from
the N-best list that yield the highest BLEU score. The algorithm that does
this is approximate, because actually finding the highest BLEU score is 
intractable (See footnote 8 of 
<a href="http://www.mt-archive.info/AMTA-2006-Lopez.pdf">this paper</a>
for an explanation). But even though this is not a true upper bound on the BLEU
score, you can see that there is quite a lot of room for improvement.
</p>

<p>Of course, you will not be able to submit oracle translations for the
assignment, because you don't have reference translations for the last 250 
sentences of the test set. So you will need to develop a way to choose 
better sentences from the N-best list without access to a reference. To help
you in this task, we have provided you with some training data (which includes
both N-best lists and reference sentences) and a very simple implementation
of the <a href="">pairwise ranking optimization</a> (PRO) algorithm, using a
<a href="http://en.wikipedia.org/wiki/Perceptron">perceptron</a> as its underlying classifier.
PRO attempts to optimize translation quality towards BLEU
score, the metric on which we evaluate. It produces a vector of weights for the
features on the translations in the N-best list. The reranker can read this
weight vector with the <tt>-w</tt> option. It takes the dot
product of the weight vector and the feature values to rank the candidate 
translations, choosing the best one for each sentence. To run this
process, type:
</p>

<p><pre>learn | rerank -w - | grade</pre></p>

<p>You should observe that the BLEU score improves slightly. The <tt>learn</tt>
program contains several parameters that you can optionally vary, which may
improve accuracy.</p>

<a name="challenge"></a>
<h2>The Challenge</h2>

<p>Improving the model should cause the BLEU score to increase even more. 
Your task for this assignment is to <b>improve the BLEU score
as much as possible, subject to the constraint that your translations
must come from the N-best list
</b>. While it is possible to do even better by considering candidate
translations that are not in the N-best list, for this task you should 
focus on simply choosing the best translation from among the ones we
have given you, rather than attempting to generate new candidates.
Whoever obtains the highest BLEU score will receive the most points.
<p>

<p>There are various ways that you might improve on the default system.
It is quite likely that simply varying some of the parameters to the PRO
algorithm will yield an improvement. However, there are many other ways
that you might improve the reranker. These might include:
</p> 

<ul class="real">
<li><a href="http://aclweb.org/anthology-new/W/W08/W08-0302.pdf">Adding new, informative features!</a>
<li><a href="http://aclweb.org/anthology-new/P/P03/P03-1021.pdf">
Implementing Och's minimum error rate algorithm</a> 
(Note: there are many alternative descriptions of this algorithm, 
e.g. Algorithm 1 of 
<a href="http://www.cs.jhu.edu/~alopez/papers/survey.pdf">this survey paper</a>).
</li>
<li>...Or one of its <a href="http://aclweb.org/anthology-new/D/D11/D11-1004.pdf">many</a> 
<a href="http://aclweb.org/anthology-new/W/W08/W08-0304.pdf">variants</a>.
</li>
<li>Replacing the underlying classifier used by PRO.</li>
</ul>

<p>But the sky's the limit! Alignment isn't a solved problem, and you 
   should experiment to see how well you can do. Who knows? Maybe you'll
   develop the next state-of-the-art alignment algorithm!
</p>
